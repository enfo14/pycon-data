{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018 PyCon UK - Understanding sample bias in surveys about web services\n",
    "\n",
    "**A fundamental problem of applying surveys about specialised topics or designed for a particular community is the underlying sample bias. We have designed a simple survey that asks respondents to score a set of web services in several aspects, including the quality of their software, their social and environmental impact, and their efforts in user experience (UX) and customer support. The survey has been applied separately to the developer team at Omni Digital, and to the attendees at *2018 PyCon UK*, which took place between 15/09 and 19/09.**\n",
    "\n",
    "The following analysis cleans up the data and uses a two-sample Kolmogorov-Smirnov test to assess whether there are any differences between the distributions of scores throughout the entire dataset, for each attribute. This is a first step towards a method to effectively recognise and assess fundamental differences in concept between two communities, as well as to explore the possibility that specialised knowledge may have a direct influence in the wider scope of things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell reads the data from the API and cleans it up, removing unnecessary fields\n",
    "fulldf = pd.read_json(\"http://pycon-data.omni-digital.co.uk/api/v1/survey_instances/?format=json\")\n",
    "df = fulldf[['completed_at', 'name', 'main', 'support', 'social', 'total']]\n",
    "df = df.set_index('completed_at')\n",
    "\n",
    "# All surveys corresponding to the Omni Digital team were taken on 14/09, while PyCon was held 15/09 to 19/09.\n",
    "omni = df[:pd.datetime(2018,9,14,23,59)]\n",
    "pycon = df[pd.datetime(2018,9,15):pd.datetime(2018,9,19,23,59)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can obtain some basic information about the data set, including the list of services and the number of surveys\n",
    "services = df.name.unique()\n",
    "print(f\"The following services have been used:\")\n",
    "for service in services:\n",
    "    print(f\"\\t{service}\")\n",
    "\n",
    "total_count = fulldf.login.unique().size\n",
    "omni_count = omni.loc[omni['name'] == 'Facebook'].name.count()\n",
    "pycon_count = pycon.loc[pycon['name'] == 'Facebook'].name.count()\n",
    "\n",
    "print(f\"\\nA total of {total_count} surveys have been submitted, of which:\")\n",
    "print(f\"\\t{omni_count} are from Omni Digital\")\n",
    "print(f\"\\t{pycon_count} are from 2018 PyCon UK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Omni Digital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "services = omni.groupby('name').mean().sort_values('total', ascending=False)\n",
    "services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omni_boxplot = services.boxplot()\n",
    "plt.ylim([0,10])\n",
    "omni_boxplot_ylabel = plt.ylabel(f\"Average score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The box plot shows us that, generally, the `main` scores are higher and have larger dispersion than those in `support` and `social` aspects. However, this plot ignores the dispersion within the scoring of each service, and only compares across services.\n",
    "\n",
    "On the other hand, if we calculate the probability mass function (pmf) and the cumulative mass function (cmf) across the entire dataset, the dispersion is better accounted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = pd.interval_range(start=-0.5, end=10.5)\n",
    "omni_freq = omni.drop(['name'], axis=1).apply(pd.Series.value_counts, sort=False, bins=bins)\n",
    "omni_pmf = omni_freq/np.sum(omni_freq)\n",
    "omni_cmf = np.cumsum(omni_pmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in omni_cmf.keys():\n",
    "    plt.plot(bins.mid, omni_cmf[key])\n",
    "\n",
    "legend = plt.legend()\n",
    "xlabel = plt.xlabel(f\"Score\")\n",
    "ylabel = plt.ylabel(f\"Cumulative mass function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there seems to be an alignment of the scores in `social` and `support` attributes, but the `main` scores seem to follow a different distribution. We can test whether this assumption is statistically significant using a two-sample Kolmogorov-Smirnov test. The statistic is calculated as the supremum of the absolute differences:\n",
    "\n",
    "$$ D_{n,m} = \\sup_x \\left| F_{1,n}(x) - F_{2,m}(x) \\right|,$$\n",
    "\n",
    "and the null hypothesis, which can be phrased as \"_the two samples are drawn from the same distribution_\", is rejected if:\n",
    "\n",
    "$$ D_{n,m} > c(\\alpha)\\sqrt{\\frac{n + m}{nm}}.$$\n",
    "\n",
    "In general, the value of the baseline $c(\\alpha)$ is given by:\n",
    "\n",
    "$$ c(\\alpha) = \\sqrt{-\\frac{1}{2}\\ln\\left(\\frac{\\alpha}{2}\\right)} $$\n",
    "\n",
    "Alternatively, we can calculate the p-value of a given $D_{n,m}$ with known $n$ and $m$ by re-writing the formula:\n",
    "\n",
    "$$ p\\left(D_{n,m}, n, m\\right) = 2e^{-2D_{n,m}^2\\frac{nm}{n+m}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c(a):\n",
    "    return np.sqrt(-0.5*np.log(a/2))\n",
    "\n",
    "def pval(d, n, m):\n",
    "    return 2*np.exp(-2*d**2*n*m/(n+m))\n",
    "\n",
    "used = ['total']\n",
    "for key1 in omni_cmf.drop(used, axis=1).keys():\n",
    "    n = np.sum(omni_freq[key1])\n",
    "    used.append(key1)\n",
    "    for key2 in omni_cmf.drop(used, axis=1).keys():\n",
    "        m = np.sum(omni_freq[key2])\n",
    "        dnm = np.max(np.abs(omni_cmf[key1]-omni_cmf[key2]))\n",
    "        ca = c(0.05)*np.sqrt((n+m)/(n*m))\n",
    "        pv = pval(dnm, n, m)\n",
    "        \n",
    "        print(f\"{key1}\\t{key2}\\t{dnm}\\t{ca}\\t{pv}\\t{dnm>ca}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results show that there is a significant difference between the distributions obtained for the `main` scores and the `social` and `support` scores. It is a good indicator that, generally, the expectations of the respondents are different for each attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,5])\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(omni.main, omni.social, 'ko');\n",
    "plt.xlabel(f\"Main\");\n",
    "plt.ylabel(f\"Social\");\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(omni.main, omni.support, 'ko');\n",
    "plt.xlabel(f\"Main\");\n",
    "plt.ylabel(f\"Support\");\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(omni.social, omni.support, 'ko');\n",
    "plt.xlabel(f\"Social\");\n",
    "plt.ylabel(f\"Support\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omni.drop(['name', 'total'], axis=1).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2018 PyCon UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "services = pycon.groupby('name').mean().sort_values('total', ascending=False)\n",
    "services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycon_boxplot = services.boxplot()\n",
    "plt.ylim([0,10])\n",
    "pycon_boxplot_ylabel = plt.ylabel(f\"Average score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The box plot shows us that, similarly to the Omni dataset, the `main` scores are slightly higher than those in `support` and `social` aspects. However, this plot ignores the dispersion within the scoring of each service, and only compares across services.\n",
    "\n",
    "On the other hand, if we calculate the probability mass function (pmf) and the cumulative mass function (cmf) across the entire dataset, the dispersion is better accounted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = pd.interval_range(start=-0.5, end=10.5)\n",
    "pycon_freq = pycon.drop(['name'], axis=1).apply(pd.Series.value_counts, sort=False, bins=bins)\n",
    "pycon_pmf = pycon_freq/np.sum(pycon_freq)\n",
    "pycon_cmf = np.cumsum(pycon_pmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in pycon_cmf.keys():\n",
    "    plt.plot(bins.mid, pycon_cmf[key])\n",
    "\n",
    "legend = plt.legend()\n",
    "xlabel = plt.xlabel(f\"Score\")\n",
    "ylabel = plt.ylabel(f\"Cumulative mass function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c(a):\n",
    "    return np.sqrt(-0.5*np.log(a/2))\n",
    "\n",
    "def pval(d, n, m):\n",
    "    return 2*np.exp(-2*d**2*n*m/(n+m))\n",
    "\n",
    "used = ['total']\n",
    "for key1 in pycon_cmf.drop(used, axis=1).keys():\n",
    "    n = np.sum(pycon_freq[key1])\n",
    "    used.append(key1)\n",
    "    for key2 in pycon_cmf.drop(used, axis=1).keys():\n",
    "        m = np.sum(pycon_freq[key2])\n",
    "        dnm = np.max(np.abs(pycon_cmf[key1]-pycon_cmf[key2]))\n",
    "        ca = c(0.05)*np.sqrt((n+m)/(n*m))\n",
    "        pv = pval(dnm, n, m)\n",
    "        \n",
    "        print(f\"{key1}\\t{key2}\\t{dnm}\\t{ca}\\t{pv}\\t{dnm>ca}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results show that there is a significant difference between the distributions obtained for the `main` scores and the `social` and `support` scores. It is a good indicator that, generally, the expectations of the respondents are different for each attribute. \n",
    "\n",
    "One last question remains to be answered regarding our data: are there any correlations between the attributes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,5])\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(pycon.main, pycon.social, 'ko');\n",
    "plt.xlabel(f\"Main\");\n",
    "plt.ylabel(f\"Social\");\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(pycon.main, pycon.support, 'ko');\n",
    "plt.xlabel(f\"Main\");\n",
    "plt.ylabel(f\"Support\");\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(pycon.social, pycon.support, 'ko');\n",
    "plt.xlabel(f\"Social\");\n",
    "plt.ylabel(f\"Support\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycon.drop(['name', 'total'], axis=1).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative analysis\n",
    "\n",
    "So far, the analyses conducted on each dataset have given very similar descriptions of the data, which leads us to suspect that there really are no significant differences between the Omni dataset and the PyCon one. This is a sensible hypothesis: after all, the PyCon community is composed mostly of developers, as is the team at Omni Digital. \n",
    "\n",
    "However, there are some differences in the rankings of the services. These may be a consequence of certain outliers, as the datasets are very small and any anomaly may bias the data significantly. However, it is more likely that they are simply consequence of the noise in the data. In any case, we need to check whether there are any significant differences between the two datasets. We can use the same Kolmogorov-Smirnov test to perform the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,10])\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(bins.mid, omni_cmf.main, 'k', label='Omni');\n",
    "plt.plot(bins.mid, pycon_cmf.main, 'r', label='PyCon');\n",
    "plt.xlabel(f\"Score\");\n",
    "plt.ylabel(f\"CMF\");\n",
    "plt.title(\"Main\");\n",
    "plt.legend();\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(bins.mid, omni_cmf.social, 'k', label='Omni');\n",
    "plt.plot(bins.mid, pycon_cmf.social, 'r', label='PyCon');\n",
    "plt.xlabel(f\"Score\");\n",
    "plt.ylabel(f\"CMF\");\n",
    "plt.title(\"Social\");\n",
    "plt.legend();\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(bins.mid, omni_cmf.support, 'k', label='Omni');\n",
    "plt.plot(bins.mid, pycon_cmf.support, 'r', label='PyCon');\n",
    "plt.xlabel(f\"Score\");\n",
    "plt.ylabel(f\"CMF\");\n",
    "plt.title(\"Support\");\n",
    "plt.legend();\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(bins.mid, omni_cmf.total, 'k', label='Omni');\n",
    "plt.plot(bins.mid, pycon_cmf.total, 'r', label='PyCon');\n",
    "plt.xlabel(f\"Score\");\n",
    "plt.ylabel(f\"CMF\");\n",
    "plt.title(\"Total\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual exploration reveals that the plots generally seem to look the same. We can now perform the two-sample KS test for each attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c(a):\n",
    "    return np.sqrt(-0.5*np.log(a/2))\n",
    "\n",
    "def pval(d, n, m):\n",
    "    return 2*np.exp(-2*d**2*n*m/(n+m))\n",
    "\n",
    "for key in omni_cmf.keys():\n",
    "    dnm = np.max(np.abs(omni_cmf[key]-pycon_cmf[key]))\n",
    "    m = np.sum(omni_freq[key])\n",
    "    n = np.sum(pycon_freq[key])\n",
    "    ca = c(0.05)*np.sqrt((n+m)/(n*m))\n",
    "    pv = pval(dnm, n, m)\n",
    "        \n",
    "    print(f\"{key}\\t{dnm}\\t{ca}\\t{pv}\\t{dnm>ca}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of services\n",
    "\n",
    "Having confirmed that there are no significant differences between the Omni subset and the PyCon subset, we can analyse each service separately. These analysis are less reliable due to the reduced size of their respective datasets, because each survey instance is composed of 11 services and they accumulate when averaging them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for service in df.name.unique():\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=4, squeeze=True, figsize=[18,4])\n",
    "\n",
    "    omni_freq = omni.loc[omni.name == service].drop(['name'], axis=1).apply(pd.Series.value_counts, sort=False, bins=bins)\n",
    "    omni_pmf = omni_freq / np.sum(omni_freq)\n",
    "    omni_cmf = np.cumsum(omni_pmf)\n",
    "    \n",
    "    pycon_freq = pycon.loc[pycon.name == service].drop(['name'], axis=1).apply(pd.Series.value_counts, sort=False, bins=bins)\n",
    "    pycon_pmf = pycon_freq / np.sum(pycon_freq)\n",
    "    pycon_cmf = np.cumsum(pycon_pmf)\n",
    "    \n",
    "    for i, key in enumerate(omni_freq.keys()):\n",
    "        ax = axes[i]\n",
    "        ax.plot(bins.mid, omni_cmf[key], label=\"Omni\")\n",
    "        ax.plot(bins.mid, pycon_cmf[key], label=\"PyCon\")\n",
    "        ax.set_title(f\"{service} - {key}\")\n",
    "        ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kolmogorov-Smirnov calculation would very nearly be rendered useless for such low counts of instances. For the sake of completion, we can quickly calculate it. For the maximum counts available in each subset, the threshold for a 95% confidence interval would be:\n",
    "\n",
    "$$ c(\\alpha) \\sqrt{\\frac{n+m}{nm}} = c(0.05) \\sqrt{\\frac{30}{176}} \\simeq 0.54 $$\n",
    "\n",
    "Any null responses will imply a lower count, which translates to an even higher threshold. Thus, we can safely assume that any pair of distributions with a supremum of the difference of more than 0.54 will be flagged as having significant differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for service in df.name.unique():\n",
    "    omni_freq = omni.loc[omni.name == service].drop(['name'], axis=1).apply(pd.Series.value_counts, sort=False, bins=bins)\n",
    "    omni_pmf = omni_freq / np.sum(omni_freq)\n",
    "    omni_cmf = np.cumsum(omni_pmf)\n",
    "    \n",
    "    pycon_freq = pycon.loc[pycon.name == service].drop(['name'], axis=1).apply(pd.Series.value_counts, sort=False, bins=bins)\n",
    "    pycon_pmf = pycon_freq / np.sum(pycon_freq)\n",
    "    pycon_cmf = np.cumsum(pycon_pmf)\n",
    "    \n",
    "    for key in omni_cmf.keys():\n",
    "        dnm = np.max(np.abs(omni_cmf[key] - pycon_cmf[key]))\n",
    "        if dnm > 0.54:\n",
    "            print(f\"{service} [{key}]: {dnm:.4f} - {dnm > 0.54}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the only service that significantly differs is _Reddit_, and only in the distribution of its average scores, but not in the distribution of its component scores. This is a symptom of the larger issue with this analysis: the sample size is very reduced and severely limits our ability to make guesses about the actual dispersion of the scores in the population. Nontheless, it is safe to say that the apparent differences in the rankings do not actually represent significant differences in the underlying biases and opinions of the two collectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
